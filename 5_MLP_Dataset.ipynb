{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"5_MLP_Dataset.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1SlJy6S81U0i9oKcpqktO-_vZ9L0k6cvJ","authorship_tag":"ABX9TyNqmeUh4s+e5mJ+1DztHr/o"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import numpy as np"],"metadata":{"id":"dolZnA7ScZ7c"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Dataset:\n","  def __init__(self, name, mode):\n","    self.name = name\n","    self.mode = mode\n","  \n","  def __str__(self):\n","    return '{}({}, {}+{}+{})'.format(self.name, self.mode, len(self.train_xs), len(self.test_xs), len(self.validate_xs))\n","  \n","  @property\n","  def train_count(self):\n","    return len(self.train_xs)"],"metadata":{"id":"hys5Z19VFXGC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def dataset_get_train_data(self, batch_size, nth):\n","  from_index = nth * batch_size\n","  to_index = (nth+1) * batch_size\n","\n","  train_X = self.train_xs[self.indices[from_index:to_index]]\n","  train_Y = self.train_ys[self.indices[from_index:to_index]]\n","\n","  return train_X, train_Y\n","\n","def dataset_shuffle_train_data(self, size):\n","  self.indices = np.arange(size)\n","  np.random.shuffle(self.indices)\n","\n","Dataset.get_train_data = dataset_get_train_data\n","Dataset.shuffle_train_data = dataset_shuffle_train_data"],"metadata":{"id":"IB8NWUEVF_hD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def dataset_get_test_data(self):\n","  return self.test_xs, self.test_ys \n","Dataset.get_test_data = dataset_get_test_data"],"metadata":{"id":"_9B4zZ95GXM5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def dataset_get_validate_data(self, count):\n","  self.validate_indices = np.arange(len(self.validate_xs))\n","  np.random.shuffle(self.validate_indices)\n","  validate_X = self.validate_xs[self.validate_indices[0:count]]\n","  validate_Y = self.validate_ys[self.validate_indices[0:count]]\n","  return validate_X, validate_Y\n","\n","Dataset.get_validate_data = dataset_get_validate_data\n","Dataset.get_visualize_data = dataset_get_validate_data"],"metadata":{"id":"g2nsO7r2Jabw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def dataset_shuffle_data(self, xs, ys, train_ratio=0.8, validate_ratio=0.05):\n","  data_count = len(xs)\n","\n","  train_cnt = int(data_count * train_ratio / 10) * 10\n","  validate_cnt = int(data_count * validate_ratio)\n","  test_cnt = data_count - train_cnt - validate_cnt\n","  \n","  train_from, train_to = 0, train_cnt\n","  validate_from, validate_to = train_cnt+1, train_cnt+validate_cnt\n","  test_from, test_to = train_cnt+validate_cnt, data_count\n","\n","  indices = np.arange(data_count)\n","  np.random.shuffle(indices)\n","\n","  self.train_xs = xs[indices[train_from:train_to]]\n","  self.train_ys = ys[indices[train_from:train_to]]\n","  self.validate_xs = xs[indices[validate_from:validate_to]]\n","  self.validate_ys = ys[indices[validate_from:validate_to]]\n","  self.test_xs = xs[indices[test_from:test_to]]\n","  self.test_ys = ys[indices[test_from:test_to]]\n","\n","  self.input_shape = xs[0].shape\n","  self.output_shape = ys[0].shape\n","\n","  return indices[train_from:train_to], indices[validate_from:validate_to], indices[test_from:test_to]\n","\n","Dataset.shuffle_data = dataset_shuffle_data"],"metadata":{"id":"jZqhGkhCKGpB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def dataset_forward_postproc(self, output, y, mode=None):\n","  if mode is None:\n","    mode = self.mode\n","  if mode == 'regression':\n","    diff = output - y\n","    square = np.square(diff)\n","    loss = np.mean(square)\n","    aux = diff\n","  elif mode == 'binary':\n","    entropy = sigmoid_cross_entropy_with_logits(y, output)\n","    loss = np.mean(entropy)\n","    aux = [y, output]\n","  elif mode == 'select':\n","    entropy = softmax_cross_entropy_with_logits(y, output)\n","    loss = np.mean(entropy)\n","    aux = [output, y, entropy]\n","  \n","  return loss, aux\n","\n","Dataset.forward_postproc = dataset_forward_postproc"],"metadata":{"id":"l495eIoLK0vB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def dataset_backprop_postproc(self, G_loss, aux, mode=None):\n","  if mode is None:\n","    mode = self.mode\n","  \n","  if mode == 'regression':\n","    diff = aux\n","    shape = diff.shape\n","\n","    g_loss_square = np.ones(shape) / np.prod(shape)\n","    g_square_diff = 2 * diff\n","    g_diff_output = 1\n","\n","    G_square = g_loss_square * G_loss\n","    G_diff = g_square_diff * G_square\n","    G_output = g_diff_output * G_diff\n","  elif mode == 'binary':\n","    y, output = aux\n","    shape = output.shape\n","    g_loss_entropy = np.ones(shape) / np.prod(shape)\n","    g_entropy_output = sigmoid_cross_entropy_with_logits_derv(y, output)\n","\n","    G_entropy = g_loss_entropy * G_loss\n","    G_output = g_entropy_output * G_entropy\n","  elif mode == 'select':\n","    output, y, entropy = aux\n","    g_loss_entropy = 1.0 / np.prod(entropy.shape)\n","    g_entropy_output = softmax_cross_entropy_with_logits_derv(y, output)\n","    G_entropy = g_loss_entropy * G_loss\n","    G_output = g_entropy_output * G_entropy\n","  \n","  return G_output\n","Dataset.backprop_postproc = dataset_backprop_postproc"],"metadata":{"id":"cyk-b2enNc_T"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def dataset_eval_accuracy(self, x, y, output, mode=None):\n","  if mode is None:\n","    mode = self.mode\n","\n","  if mode == 'regression':\n","    mse = np.mean(np.square(output - y))\n","    accuracy = 1 - np.sqrt(mse) / np.mean(y)\n","  elif mode == 'binary':\n","    estimate = np.greater(output, 0)\n","    answer = np.equal(y, 1.0)\n","    correct = np.equal(estimate, answer)\n","    accuracy = np.mean(correct)  \n","  elif mode == 'select':\n","    estimate = np.argmax(output, axis=1)\n","    answer = np.argmax(y, axis=1)\n","    correct = np.equal(estimate, answer)\n","    accuracy = np.mean(correct)\n","  return accuracy\n","\n","Dataset.eval_accuracy = dataset_eval_accuracy"],"metadata":{"id":"wWEAfayFVXbD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def dataset_get_estimate(self, output, mode=None):\n","  if mode is None: mode = self.mode\n","\n","  if mode == 'regression':\n","    estimate = output\n","  elif mode == 'binary':\n","    estimate = sigmoid(output)\n","  elif mode == 'select':\n","    estimate = softmax(output)\n","  return estimate\n","\n","Dataset.get_estimate = dataset_get_estimate"],"metadata":{"id":"ZLYaCBDizWrC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def dataset_train_prt_result(self, epoch, costs, accs, acc, time1, time2):\n","  print('Epoch {}: cost={:5.3f}, accuracy={:5.3f}/{:5.3f} ({}/{} secs)'.\\\n","        format(epoch, np.mean(costs), np.mean(accs), acc, time1, time2))\n","\n","def dataset_test_prt_result(self, name, acc, time):\n","  print('Model {} test report: accuracy={:5.3f}, ({} secs)\\n'.format(name, acc, time))\n","\n","Dataset.train_prt_result = dataset_train_prt_result\n","Dataset.test_prt_result = dataset_test_prt_result"],"metadata":{"id":"2ewsMzlpZKE1"},"execution_count":null,"outputs":[]}]}