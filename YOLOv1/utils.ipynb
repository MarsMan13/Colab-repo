{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"utils.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMjiIsQf2/PHq03tv3XH1kc"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":16,"metadata":{"id":"-zGF3P0dmMZE","executionInfo":{"status":"ok","timestamp":1649575251229,"user_tz":-540,"elapsed":374,"user":{"displayName":"G.M. C","userId":"01123269045867249031"}}},"outputs":[],"source":["import torch\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import matplotlib.patches as patches\n","from collections import Counter"]},{"cell_type":"code","source":["def intersection_over_union(boxes_preds, boxes_labels, box_format=\"midpoint\"):\n","    \"\"\"\n","    Calculates intersection over union\n","    Parameters:\n","        boxes_preds (tensor): Predictions of Bounding Boxes (BATCH_SIZE, 4)\n","        boxes_labels (tensor): Correct labels of Bounding Boxes (BATCH_SIZE, 4)\n","        box_format (str): midpoint/corners, if boxes (x,y,w,h) or (x1,y1,x2,y2)\n","    Returns:\n","        tensor: Intersection over union for all examples\n","    \"\"\"\n","\n","    if box_format == \"midpoint\":\n","        box1_x1 = boxes_preds[..., 0:1] - boxes_preds[..., 2:3] / 2\n","        box1_y1 = boxes_preds[..., 1:2] - boxes_preds[..., 3:4] / 2\n","        box1_x2 = boxes_preds[..., 0:1] + boxes_preds[..., 2:3] / 2\n","        box1_y2 = boxes_preds[..., 1:2] + boxes_preds[..., 3:4] / 2\n","        box2_x1 = boxes_labels[..., 0:1] - boxes_labels[..., 2:3] / 2\n","        box2_y1 = boxes_labels[..., 1:2] - boxes_labels[..., 3:4] / 2\n","        box2_x2 = boxes_labels[..., 0:1] + boxes_labels[..., 2:3] / 2\n","        box2_y2 = boxes_labels[..., 1:2] + boxes_labels[..., 3:4] / 2\n","\n","    if box_format == \"corners\":\n","        box1_x1 = boxes_preds[..., 0:1]\n","        box1_y1 = boxes_preds[..., 1:2]\n","        box1_x2 = boxes_preds[..., 2:3]\n","        box1_y2 = boxes_preds[..., 3:4]  # (N, 1)\n","        box2_x1 = boxes_labels[..., 0:1]\n","        box2_y1 = boxes_labels[..., 1:2]\n","        box2_x2 = boxes_labels[..., 2:3]\n","        box2_y2 = boxes_labels[..., 3:4]\n","\n","    x1 = torch.max(box1_x1, box2_x1)\n","    y1 = torch.max(box1_y1, box2_y1)\n","    x2 = torch.min(box1_x2, box2_x2)\n","    y2 = torch.min(box1_y2, box2_y2)\n","\n","    # .clamp(0) is for the case when they do not intersect\n","    intersection = (x2 - x1).clamp(0) * (y2 - y1).clamp(0)\n","\n","    box1_area = abs((box1_x2 - box1_x1) * (box1_y2 - box1_y1))\n","    box2_area = abs((box2_x2 - box2_x1) * (box2_y2 - box2_y1))\n","\n","    return intersection / (box1_area + box2_area - intersection + 1e-6)"],"metadata":{"id":"8BjC108ps8dy","executionInfo":{"status":"ok","timestamp":1649575251598,"user_tz":-540,"elapsed":3,"user":{"displayName":"G.M. C","userId":"01123269045867249031"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["from PIL import Image, ImageDraw, ImageFont\n","from torchvision.transforms.functional import to_tensor, to_pil_image"],"metadata":{"id":"2qdVmjlVJyI6","executionInfo":{"status":"ok","timestamp":1649575251598,"user_tz":-540,"elapsed":3,"user":{"displayName":"G.M. C","userId":"01123269045867249031"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["def get_bboxes(\n","    loader,\n","    model,\n","    iou_threshold,\n","    threshold,\n","    pred_format=\"cells\",\n","    box_format=\"midpoint\",\n","    device=\"cuda\",\n","):\n","  all_pred_boxes = []\n","  all_true_boxes = []\n","  \n","  model.eval()\n","  train_index = 0\n","\n","  for batch_index, (x, labels) in enumerate(loader):\n","    x = x.to(device)\n","    labels = labels.to(device)\n","\n","    with torch.no_grad():\n","      predictions = model(x)\n","    \n","    batch_size = x.shape[0]\n","    #true_bboxes = cellboxes_to_boxes(labels)\n","    true_bboxes = cellboxes_to_boxes(torch.concat([labels, labels[..., 20:25]], dim=-1))\n","    bboxes = cellboxes_to_boxes(predictions)\n","\n","    for index in range(batch_size):\n","      nms_boxes = non_max_suppression(\n","          bboxes[index],\n","          iou_threshold=iou_threshold,\n","          threshold=threshold,\n","          box_format=box_format\n","      )\n","\n","      for nms_box in nms_boxes:\n","        all_pred_boxes.append([train_index] + nms_box)\n","      for box in true_bboxes[index]:\n","        if box[1] > threshold:\n","          all_true_boxes.append([train_index] + box)\n","      train_index += 1\n","  model.train()\n","  return all_pred_boxes, all_true_boxes\n"],"metadata":{"id":"qinBgqDJtSRN","executionInfo":{"status":"ok","timestamp":1649575251598,"user_tz":-540,"elapsed":2,"user":{"displayName":"G.M. C","userId":"01123269045867249031"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["def convert_cellboxes(predictions, S=7):\n","  predictions = predictions.to(\"cpu\")\n","  batch_size = predictions.shape[0]\n","  predictions = predictions.reshape(batch_size, S, S, 30)\n","  bboxes1 = predictions[..., 21:25]\n","  bboxes2 = predictions[..., 26:30]\n","  scores = torch.cat(\n","      (predictions[..., 20].unsqueeze(0), predictions[..., 25].unsqueeze(0)), dim=0\n","  )\n","  best_box = scores.argmax(0).unsqueeze(-1)\n","  best_boxes = bboxes1 * (1 - best_box) + best_box * bboxes2            # (Batch, 7, 7, 4)\n","  cell_indices = torch.arange(7).repeat(batch_size, 7, 1).unsqueeze(-1) # (Batch, 7, 7, 1)\n","  x = 1 / S * (best_boxes[..., :1] + cell_indices)                      # x, y : 0. ~ 1.\n","  y = 1 / S * (best_boxes[..., 1:2] + cell_indices.permute(0, 2, 1, 3)) \n","  w_h = 1 / S * best_boxes[..., 2:4]\n","  converted_bboxes = torch.cat((x, y, w_h), dim=-1) # (Batch, 7, 7, 4)\n","  predicted_class = predictions[..., :20].argmax(-1).unsqueeze(-1)  # (Batch, 7, 7, 1)\n","  best_confidence = torch.max(predictions[..., 20], predictions[..., 25]).unsqueeze(-1)\n","\n","  converted_preds = torch.cat((predicted_class, best_confidence, converted_bboxes), dim=-1)\n","\n","  return converted_preds  # (Batch, 7, 7, 6)\n"],"metadata":{"id":"o_YV0MhGJqKK","executionInfo":{"status":"ok","timestamp":1649575251914,"user_tz":-540,"elapsed":318,"user":{"displayName":"G.M. C","userId":"01123269045867249031"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["def cellboxes_to_boxes(out, S=7):\n","  converted_pred = convert_cellboxes(out).reshape(out.shape[0], S * S, -1)  # (Batch, 7 * 7, 6)\n","  converted_pred[..., 0] = converted_pred[..., 0].long()\n","  all_bboxes = []\n","\n","  for batch_index in range(out.shape[0]):\n","    bboxes = []\n","    for bbox_index in range(S * S):\n","      bboxes.append([x.item() for x in converted_pred[batch_index, bbox_index, :]])\n","    all_bboxes.append(bboxes)\n","  return all_bboxes # list: (Batch, S * S, 6)"],"metadata":{"id":"SoL34EUcj31M","executionInfo":{"status":"ok","timestamp":1649575251914,"user_tz":-540,"elapsed":4,"user":{"displayName":"G.M. C","userId":"01123269045867249031"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["test_input = torch.randn(16, 7, 7, 30)\n","ret = cellboxes_to_boxes(test_input)"],"metadata":{"id":"7Xwcw1P0mGHA","executionInfo":{"status":"ok","timestamp":1649575251914,"user_tz":-540,"elapsed":4,"user":{"displayName":"G.M. C","userId":"01123269045867249031"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["def non_max_suppression(bboxes, iou_threshold, threshold, box_format=\"corners\"):\n","  # iou_threshold = 0.5, threshold = 0.4\n","  assert type(bboxes) == list\n","\n","  bboxes = [box for box in bboxes if box[1] > threshold]\n","  bboxes = sorted(bboxes, key=lambda x: x[1], reverse=True)\n","  bboxes_after_nms = []  # result\n","\n","  while bboxes:\n","    cur_box = bboxes.pop(0)\n","    bboxes = [\n","              box\n","              for box in bboxes\n","              if box[0] != cur_box[0]\n","              or intersection_over_union(\n","                  torch.tensor(cur_box[2:]),\n","                  torch.tensor(box[2:]),\n","                  box_format=box_format\n","              )\n","              < iou_threshold\n","    ]\n","    bboxes_after_nms.append(cur_box)\n","  return bboxes_after_nms"],"metadata":{"id":"-gZobrxinFgR","executionInfo":{"status":"ok","timestamp":1649575251915,"user_tz":-540,"elapsed":5,"user":{"displayName":"G.M. C","userId":"01123269045867249031"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["from collections import Counter\n","\n","def mean_average_precision(\n","    pred_boxes, true_boxes, iou_threshold=0.5, box_format=\"midpoint\", num_classes=20\n","):\n","  \"\"\"\n","  Calculates mean average precision \n","  Parameters:\n","      pred_boxes (list): list of lists containing all bboxes with each bboxes\n","      specified as [train_idx, class_prediction, prob_score, x1, y1, x2, y2]\n","      true_boxes (list): Similar as pred_boxes except all the correct ones \n","      iou_threshold (float): threshold where predicted bboxes is correct\n","      box_format (str): \"midpoint\" or \"corners\" used to specify bboxes\n","      num_classes (int): number of classes\n","  Returns:\n","      float: mAP value across all classes given a specific IoU threshold \n","  \"\"\"\n","\n","  # list storing all AP for respective classes\n","  average_precisions = []\n","\n","  # used for numerical stability later on\n","  epsilon = 1e-6\n","\n","  for c in range(num_classes):\n","      detections = []\n","      ground_truths = []\n","\n","      # Go through all predictions and targets,\n","      # and only add the ones that belong to the\n","      # current class c\n","      for detection in pred_boxes:\n","          if detection[1] == c:\n","              detections.append(detection)\n","\n","      for true_box in true_boxes:\n","          if true_box[1] == c:\n","              ground_truths.append(true_box)\n","\n","      # find the amount of bboxes for each training example\n","      # Counter here finds how many ground truth bboxes we get\n","      # for each training example, so let's say img 0 has 3,\n","      # img 1 has 5 then we will obtain a dictionary with:\n","      # amount_bboxes = {0:3, 1:5}\n","      amount_bboxes = Counter([gt[0] for gt in ground_truths])\n","\n","      # We then go through each key, val in this dictionary\n","      # and convert to the following (w.r.t same example):\n","      # ammount_bboxes = {0:torch.tensor[0,0,0], 1:torch.tensor[0,0,0,0,0]}\n","      for key, val in amount_bboxes.items():\n","          amount_bboxes[key] = torch.zeros(val)\n","\n","      # sort by box probabilities which is index 2\n","      detections.sort(key=lambda x: x[2], reverse=True)\n","      TP = torch.zeros((len(detections)))\n","      FP = torch.zeros((len(detections)))\n","      total_true_bboxes = len(ground_truths)\n","      \n","      # If none exists for this class then we can safely skip\n","      if total_true_bboxes == 0:\n","          continue\n","\n","      for detection_idx, detection in enumerate(detections):\n","          # Only take out the ground_truths that have the same\n","          # training idx as detection\n","          ground_truth_img = [\n","              bbox for bbox in ground_truths if bbox[0] == detection[0]\n","          ]\n","\n","          num_gts = len(ground_truth_img)\n","          best_iou = 0\n","\n","          for idx, gt in enumerate(ground_truth_img):\n","              iou = intersection_over_union(\n","                  torch.tensor(detection[3:]),\n","                  torch.tensor(gt[3:]),\n","                  box_format=box_format,\n","              )\n","\n","              if iou > best_iou:\n","                  best_iou = iou\n","                  best_gt_idx = idx\n","\n","          if best_iou > iou_threshold:\n","              # only detect ground truth detection once\n","              if amount_bboxes[detection[0]][best_gt_idx] == 0:\n","                  # true positive and add this bounding box to seen\n","                  TP[detection_idx] = 1\n","                  amount_bboxes[detection[0]][best_gt_idx] = 1\n","              else:\n","                  FP[detection_idx] = 1\n","\n","          # if IOU is lower then the detection is a false positive\n","          else:\n","              FP[detection_idx] = 1\n","\n","      TP_cumsum = torch.cumsum(TP, dim=0)\n","      FP_cumsum = torch.cumsum(FP, dim=0)\n","      recalls = TP_cumsum / (total_true_bboxes + epsilon)\n","      precisions = torch.divide(TP_cumsum, (TP_cumsum + FP_cumsum + epsilon))\n","      precisions = torch.cat((torch.tensor([1]), precisions))\n","      recalls = torch.cat((torch.tensor([0]), recalls))\n","      # torch.trapz for numerical integration\n","      average_precisions.append(torch.trapz(precisions, recalls))\n","\n","  return sum(average_precisions) / len(average_precisions)\n"],"metadata":{"id":"ZtmGom235vT2","executionInfo":{"status":"ok","timestamp":1649575251915,"user_tz":-540,"elapsed":4,"user":{"displayName":"G.M. C","userId":"01123269045867249031"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["def plot_image(image, boxes):\n","  img = to_pil_image(image)\n","  draw = ImageDraw.Draw(img)\n","  W, H = img.size\n","\n","  for box in boxes: # box : tensor(6,) [class, prob_score, center_x, center_y, w, h]\n","    color = np.random.randint(0, 255, size=(3,), dtype=\"uint8\").tolist()\n","    x_converted, y_converted, width_converted, height_converted = (\n","        box[2] * W,\n","        box[3] * H,\n","        box[4] * W,\n","        box[5] * H\n","    )\n","    left_top, right_bot = (\n","        ((x_converted - width_converted / 2), (y_converted + height_converted / 2)),\n","        ((x_converted + width_converted / 2), (y_converted - height_converted / 2))\n","    )\n","    draw.rectangle((left_top, right_bot), outline=tuple(color), width=3)\n","    draw.text((x_converted - width_converted/2, y_converted - height_converted/2),\\\n","              classes[int(box[0])], fill=(255, 255, 255, 0))\n","  plt.figure(figsize=(8, 8))\n","  plt.imshow(img)\n","  plt.show()"],"metadata":{"id":"N06vKplxDctV","executionInfo":{"status":"ok","timestamp":1649576121669,"user_tz":-540,"elapsed":228,"user":{"displayName":"G.M. C","userId":"01123269045867249031"}}},"execution_count":63,"outputs":[]},{"cell_type":"code","source":["def showImage(img, label_matrix, C=7):\n","  # img:tensor (7,7,3)\n","  # label_matrix:tensor (7, 7, 25) or (7, 7, 30)\n","  img = to_pil_image(img)\n","  draw = ImageDraw.Draw(img)\n","  W, H = img.size\n","  \n","  cell_size_i, cell_size_j = img.size[1] / C, img.size[0] / C\n","  for i in range(C):\n","    for j in range(C):\n","      if label_matrix.size(-1) == 25 and label_matrix[20] == 1:\n","        color = np.random.randint(0, 255, size=(3,), dtype=\"uint8\").tolist()\n","        x_converted, y_converted, width_converted, height_converted = (\n","          cell_size_j * (j + label_matrix[21]),\n","          cell_size_i * (i + label_matrix[22]),\n","          cell_size_j * label_matrix[23],\n","          cell_size_i * label_matrix[24],\n","        )\n","\n","        left_top = (x_converted - width_converted / 2), (y_converted + height_converted / 2)\n","        right_bot = (x_converted + width_converted / 2), (y_converted - height_converted / 2)\n","        draw.rectangle((left_top, right_bot), outline=tuple(color), width=3)\n","  plt.figure(figsize=(15, 15))\n","  plt.imshow(img)\n"],"metadata":{"id":"W-dqJGEps9lu","executionInfo":{"status":"ok","timestamp":1649575251915,"user_tz":-540,"elapsed":4,"user":{"displayName":"G.M. C","userId":"01123269045867249031"}}},"execution_count":26,"outputs":[]}]}