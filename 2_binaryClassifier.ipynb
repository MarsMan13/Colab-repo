{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"2_binaryClassifier.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1j0xjGEladGmRLjLTn9YxhxCsNKTXUDwo","authorship_tag":"ABX9TyMrdhZN4VCDKMoPqs0/tfuI"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"HuwXffYt3tBA"},"outputs":[],"source":["import numpy as np\n","import csv"]},{"cell_type":"code","source":["RND_MEAN = 0\n","RND_STD = 0.0030\n","LEARNING_RATE = 0.01"],"metadata":{"id":"5q5docZ7CUID"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def pulsar_exec(epoch_count=40, mb_size=20, report=1, adjust_ratio=False):\n","  load_pulsar_dataset(adjust_ratio)\n","  init_model()\n","  train_and_test(epoch_count, mb_size, report)"],"metadata":{"id":"nKvtAs_b32xc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def load_pulsar_dataset(adjust_ratio):\n","  pulsars, stars = [], []\n","  with open(\"/content/drive/MyDrive/ml-data/Pulsar/pulsar_stars.csv\") as csvfile:\n","    csvreader = csv.reader(csvfile)\n","    next(csvreader,None)\n","    for row in csvreader:\n","      if row[8] == '1': pulsars.append(row)\n","      else:             stars.append(row)\n","  global data, input_cnt, output_cnt\n","  input_cnt, output_cnt = 8, 1\n","\n","  star_cnt, pulsar_cnt = len(stars), len(pulsars)\n","  if adjust_ratio == True:\n","    data = np.zeros((2 * star_cnt, 9))\n","    data[:star_cnt, :] = np.asarray(stars, dtype=\"float32\")\n","    for n in range(star_cnt):\n","      data[star_cnt+n] = np.asarray(pulsars[n % pulsar_cnt], dtype=\"float32\")\n","  else:\n","    data = np.zeros((star_cnt + pulsar_cnt, 9))\n","    data[0:star_cnt, :] = np.asarray(stars, dtype=\"float32\")\n","    data[star_cnt:, :] = np.asarray(pulsars, dtype=\"float32\")   "],"metadata":{"id":"zTRZTScE4El_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train_and_test(epoch_count, mb_size, report):\n","  step_count = arrange_data(mb_size)\n","  test_x, test_y = get_test_data()\n","  for epoch in range(epoch_count):\n","    losses = []\n","    for n in range(step_count):\n","      train_x, train_y = get_train_data(mb_size, n)\n","      loss, _ = run_train(train_x, train_y)\n","      losses.append(loss)\n","    if report > 0 and (epoch + 1) % report == 0:\n","      acc = run_test(test_x, test_y)\n","      acc_str = \", \".join(['%5.3f']*4) % tuple(acc)\n","      print(\"Epoch {} | loss:{:5.3f}, result={}\".\\\n","            format(epoch+1, np.mean(losses), acc_str))\n","  final_acc = run_test(test_x, test_y)\n","  final_acc_str = \", \".join(['%5.3f']*4) % tuple(final_acc)\n","  print(\"\\nFinal Test : final result = {}\".format(final_acc_str))"],"metadata":{"id":"g3b56R1eC86O","executionInfo":{"status":"ok","timestamp":1642514817283,"user_tz":-540,"elapsed":282,"user":{"displayName":"G.M. C","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01123269045867249031"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["def run_train(x, y):\n","  output, aux_nn = forward_neuralnet(x)\n","  loss, aux_pp = forward_postproc(output, y)\n","  accuracy = eval_accuracy(output, y)\n","\n","  G_loss = 1.0\n","  G_output = backprop_postproc(G_loss, aux_pp)\n","  backprop_neuralnet(G_output, aux_nn)\n","  return loss, accuracy\n","\n","def run_test(x, y):\n","  output, _ = forward_neuralnet(x)\n","  accuracy = eval_accuracy(output, y)\n","  return accuracy"],"metadata":{"id":"JOlIJ-JzFDPu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def forward_neuralnet(x):\n","  global weight, bias\n","  output = np.matmul(x, weight) + bias\n","  return output, x\n","\n","def backprop_neuralnet(G_output, x):\n","  global weight, bias\n","  g_output_w = x.transpose()\n","  G_w = np.matmul(g_output_w, G_output)\n","  G_b = np.sum(G_output, axis=0)\n","\n","  weight -= LEARNING_RATE * G_w\n","  bias -= LEARNING_RATE * G_b"],"metadata":{"id":"taP8yF_eGsPA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def forward_postproc(output, y):\n","  entropy = sigmoid_cross_entropy_with_logits(y, output)\n","  loss = np.mean(entropy)\n","  return loss, [y, output, entropy]\n","\n","def backprop_postproc(G_loss, aux):\n","  y, output, entropy = aux\n","\n","  g_loss_entropy = 1.0 / np.prod(entropy.shape)\n","  g_entropy_output = sigmoid_cross_entropy_with_logits_derv(y, output)\n","  \n","  G_entropy = g_loss_entropy * G_loss\n","  G_output = g_entropy_output * G_entropy\n","  return G_output\n","   "],"metadata":{"id":"XQCGJHkq71Df"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def safe_div(p, q):\n","  p, q = float(p), float(q)\n","  if np.abs(q) < 1.e-20: return np.sign(p)\n","  return p / q\n","\n","def eval_accuracy(output, y):\n","  tt = np.greater(y, 0.5)\n","  pp = np.greater(output, 0)\n","  ff = np.logical_not(tt)\n","  nn = np.logical_not(pp)\n","\n","  tp = np.sum(np.logical_and(tt, pp))\n","  fp = np.sum(np.logical_and(ff, pp))\n","  tn = np.sum(np.logical_and(tt, nn))\n","  fn = np.sum(np.logical_and(ff, nn))\n","\n","  accuracy = safe_div(tp+fn, tp+fp+tn+fn)\n","  precision = safe_div(tp, tp+fp)\n","  recall = safe_div(tp, tp+tn)\n","  f1 = 2 * safe_div(precision * recall, precision + recall)\n","\n","  return [accuracy, precision, recall, f1]"],"metadata":{"id":"JFFvTRa9T0uP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def relu(x):\n","  return np.maximum(x, 0)\n","\n","def sigmoid(x):\n","  return np.exp(-relu(-x)) / (1.0 + np.exp(-np.abs(x)))\n","\n","def sigmoid_derv(x, y):\n","  return y * (1. - y)\n","\n","def sigmoid_cross_entropy_with_logits(z, x):\n","  return relu(x) - x * z + np.log(1 + np.exp(-np.abs(x)))\n","\n","def sigmoid_cross_entropy_with_logits_derv(z, x):\n","  return -z + sigmoid(x)"],"metadata":{"id":"hamdfKlsHFVe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def init_model():\n","  global weight, bias, input_cnt, output_cnt\n","  weight = np.random.normal(RND_MEAN, RND_STD, (input_cnt, output_cnt))\n","  bias = np.zeros((output_cnt))"],"metadata":{"id":"czFf4LnPCaoz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def arrange_data(mb_size):\n","  global data, shuffle_map, test_begin_index\n","  shuffle_map = np.arange(data.shape[0])\n","  np.random.shuffle(shuffle_map)\n","  step_count = int(data.shape[0] * 0.8) // mb_size\n","  test_begin_index = step_count * mb_size\n","  return step_count\n","\n","def get_test_data():\n","  global data, shuffle_map, test_begin_index\n","  test_index = shuffle_map[test_begin_index:]\n","  test_data = data[test_index]\n","  return test_data[:, :-output_cnt], test_data[:, -output_cnt:]\n","\n","def get_train_data(mb_size, nth):\n","  global data, shuffle_map, test_begin_index, output_cnt\n","  if nth == 0:\n","    np.random.shuffle(shuffle_map[:test_begin_index])\n","  train_data = data[shuffle_map[mb_size * nth : mb_size * (nth + 1)]]\n","  return train_data[:, :-output_cnt], train_data[:, -output_cnt:]"],"metadata":{"id":"rhmRqvvhDDLk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# pulsar_exec()"],"metadata":{"id":"fLtxOfAZAron","executionInfo":{"status":"ok","timestamp":1642514272517,"user_tz":-540,"elapsed":412,"user":{"displayName":"G.M. C","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01123269045867249031"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["# pulsar_exec(adjust_ratio=True)"],"metadata":{"id":"6Vl4lhqwQBzb","executionInfo":{"status":"ok","timestamp":1642514272796,"user_tz":-540,"elapsed":3,"user":{"displayName":"G.M. C","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01123269045867249031"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"BzDV6Q5oX5de"},"execution_count":null,"outputs":[]}]}