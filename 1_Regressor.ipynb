{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"1_Regressor.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1qW8VLr9GI_c_GvZ18DjL0xs8Ecnvihn5","authorship_tag":"ABX9TyMEfyzXAD2L8uPWAEggvoDz"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vYYZdGru-Edh","executionInfo":{"status":"ok","timestamp":1642220528555,"user_tz":-540,"elapsed":8830,"user":{"displayName":"G.M. C","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01123269045867249031"}},"outputId":"ca440a6f-943f-4b81-ebb4-edc58b4d3682"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["import numpy as np\n","import csv\n","import time\n","np.random.seed(1234)"],"metadata":{"id":"pvpROWm0AMYG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# HYPER PARAMETERS\n","\n","RND_MEAN = 0\n","RND_STD = 0.0030\n","LEARNING_RATE = 0.001"],"metadata":{"id":"HK4Q2Jkk-O8B"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def abalone_exec(epoch_count=100, mb_size=10, report=1):\n","  load_abalone_dataset()\n","  init_model()\n","  train_and_test(epoch_count, mb_size, report)"],"metadata":{"id":"zSxfGCdm-WOo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def load_abalone_dataset():\n","  with open('/content/drive/MyDrive/ml-data/Abalone/abalone.csv') as csvfile:\n","    csvreader = csv.reader(csvfile)\n","    next(csvreader, None)\n","    rows = []\n","    for row in csvreader:\n","      rows.append(row)\n","  global data, input_cnt, output_cnt\n","  input_cnt, output_cnt = 10, 1\n","  data = np.zeros((len(rows), input_cnt+output_cnt))\n","  for n, row in enumerate(rows):\n","    if row[0] == 'I' : data[n, 0] = 1\n","    if row[0] == 'M' : data[n, 1] = 1\n","    if row[0] == 'F' : data[n, 2] = 1\n","    data[n, 3:] = row[1:]"],"metadata":{"id":"eU7JHQht-u_Z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def init_model():\n","  global weight, bias, input_cnt, output_cnt\n","  weight = np.random.normal(RND_MEAN, RND_STD, (input_cnt, output_cnt))\n","  bias = np.zeros((output_cnt))"],"metadata":{"id":"T4WbAPjO__8p"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train_and_test(epoch_count, mb_size, report):\n","  step_count = arrange_data(mb_size)\n","  test_x, test_y = get_test_data()\n","\n","  for epoch in range(epoch_count):\n","    losses, accs = [], []\n","\n","    for n in range(step_count):\n","      train_x, train_y = get_train_data(mb_size, n)\n","      loss, acc = run_train(train_x, train_y)\n","      losses.append(loss)\n","      accs.append(acc)\n","    if report > 0 and (epoch+1) % report == 0:\n","      acc = run_test(test_x, test_y)\n","      print(\"Epoch {}: loss:{:5.3f}, accuracy={:5.3f}/{:5.3f}\".\\\n","            format(epoch+1, np.mean(losses), np.mean(accs), acc))\n","  final_acc = run_test(test_x, test_y)\n","  print(\"\\nFinal Test : final accuracy = {:5,.3f}\".format(final_acc))"],"metadata":{"id":"o_fisQIPAaFu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Shuffle data, split train data and test data\n","def arrange_data(mb_size):\n","  global data, shuffle_map, test_begin_idx\n","  shuffle_map = np.arange(data.shape[0])\n","  np.random.shuffle(shuffle_map)\n","  step_count = int(data.shape[0] * 0.8) // mb_size\n","  test_begin_idx = step_count * mb_size\n","  return step_count # == an epoch\n","\n","def get_test_data():\n","  global data, shuffle_map, test_begin_idx\n","  test_index = shuffle_map[test_begin_idx:]\n","  test_data = data[test_index]\n","  return test_data[:, :-output_cnt], test_data[:, -output_cnt:]\n","\n","def get_train_data(mb_size, nth):\n","  global data, shuffle_map, test_begin_idx, output_cnt\n","  if nth == 0:\n","    np.random.shuffle(shuffle_map[:test_begin_idx])\n","  train_data = data[shuffle_map[mb_size * nth  : mb_size * (nth+1)]]\n","  return train_data[:, :-output_cnt], train_data[:, -output_cnt:]"],"metadata":{"id":"WJU90H4jCs6-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def run_train(x, y):\n","  output, aux_nn = forward_neuralnet(x)       # layers\n","  loss, aux_pp = forward_postproc(output, y)  # last_layer\n","  accuracy = eval_accuracy(output, y)\n","\n","  G_loss = 1.0\n","  G_output = backprop_postproc(G_loss, aux_pp)\n","  backprop_neuralnet(G_output, aux_nn)\n","  return loss, accuracy\n","\n","def run_test(x, y):\n","  output, _ = forward_neuralnet(x)\n","  accuracy = eval_accuracy(output, y)\n","  return accuracy"],"metadata":{"id":"INJXpuiQF0rk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def forward_neuralnet(x):\n","  global weight, bias\n","  output = np.matmul(x, weight) + bias\n","  return output, x\n","\n","def backprop_neuralnet(G_output, x):\n","  global weight, bias\n","  g_output_w = x.transpose()\n","\n","  G_w = np.matmul(g_output_w, G_output)\n","  G_b = np.sum(G_output, axis=0)\n","\n","  weight -= LEARNING_RATE * G_w\n","  bias -= LEARNING_RATE * G_b\n"],"metadata":{"id":"UmeSAUFiHrC1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def forward_postproc(output, y):\n","  diff = output - y\n","  square = np.square(diff)\n","  loss = np.mean(square)\n","  return loss, diff\n","\n","def backprop_postproc(G_loss, diff):\n","  shape = diff.shape\n","\n","  g_loss_square = np.ones(shape) / np.prod(shape)\n","  g_square_diff = 2 * diff\n","  g_diff_output = 1\n","\n","  G_square = g_loss_square * G_loss\n","  G_diff = g_square_diff * G_square\n","  G_output = g_diff_output * G_diff\n","\n","  return G_output\n","\n"],"metadata":{"id":"aHPX6QhtL7VJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def eval_accuracy(output, y):\n","  mdiff = np.mean(np.abs((output-y)/y))\n","  return 1 - mdiff"],"metadata":{"id":"v16Hx38YczDK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"vGHpGOzrfswH"},"execution_count":null,"outputs":[]}]}