{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"DeepLearningZeroToAll_RNN_seq2seq.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPdr3foCX0QxxlK4tBYxeH9"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Seq2Seq\n","seq를 받아서 seq를 출력하는 모델\n","ex) Chatbot\n","\n","Encoder-Decoder Architecture : RNN 두개를 이어붙인 형태"],"metadata":{"id":"vW3jpAMfnBt8"}},{"cell_type":"markdown","source":["https://github.com/deeplearningzerotoall/PyTorch/blob/master/lab-11_5_seq2seq.ipynb\n","\n","\n","https://sanghyu.tistory.com/52 : RNN/LSTM/GRU"],"metadata":{"id":"usHvDnqY5MQ-"}},{"cell_type":"code","execution_count":2,"metadata":{"id":"dU6EbRcTmimT","executionInfo":{"status":"ok","timestamp":1647436557984,"user_tz":-540,"elapsed":6112,"user":{"displayName":"G.M. C","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01123269045867249031"}}},"outputs":[],"source":["import random\n","import torch\n","import torch.nn as nn\n","from torch import optim"]},{"cell_type":"code","source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"],"metadata":{"id":"pZzc9K6vta7X","executionInfo":{"status":"ok","timestamp":1647436557984,"user_tz":-540,"elapsed":14,"user":{"displayName":"G.M. C","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01123269045867249031"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["raw = [\"I feel hungry.\t나는 배가 고프다.\",\n","       \"Pytorch is very easy.\t파이토치는 매우 쉽다.\",\n","       \"Pytorch is a framework for deep learning.\t파이토치는 딥러닝을 위한 프레임워크이다.\",\n","       \"Pytorch is very clear to use.\t파이토치는 사용하기 매우 직관적이다.\"]"],"metadata":{"id":"LezlPeEstg6k","executionInfo":{"status":"ok","timestamp":1647436557985,"user_tz":-540,"elapsed":14,"user":{"displayName":"G.M. C","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01123269045867249031"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["SOS_token = 0\n","EOS_token = 1"],"metadata":{"id":"yY7OWH-FtoTW","executionInfo":{"status":"ok","timestamp":1647436557985,"user_tz":-540,"elapsed":14,"user":{"displayName":"G.M. C","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01123269045867249031"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["class Vocab:\n","  def __init__(self):\n","    self.vocab2index = {\"<SOS>\":SOS_token, \"<EOS>\":EOS_token}\n","    self.index2vocab = {SOS_token: \"<SOS>\", EOS_token: \"<EOS>\"}\n","    self.vocab_count = {}\n","    self.n_vocab = len(self.vocab2index)\n","  \n","  def add_vocab(self, sentence):\n","    for word in sentence.split(\" \"):\n","      if word not in self.vocab2index:\n","        self.vocab2index[word] = self.n_vocab\n","        self.vocab_count[word] = 1\n","        self.index2vocab[self.n_vocab] = word\n","        self.n_vocab += 1\n","      else:\n","        self.vocab_count[word] += 1"],"metadata":{"id":"eZxAHyGPtrUN","executionInfo":{"status":"ok","timestamp":1647436557985,"user_tz":-540,"elapsed":13,"user":{"displayName":"G.M. C","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01123269045867249031"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["def filter_pair(pair, source_max_length, target_max_length):\n","  return len(pair[0].split(\" \")) < source_max_length and len(pair[1].split(\" \")) < target_max_length"],"metadata":{"id":"w-kX92jmus-x","executionInfo":{"status":"ok","timestamp":1647436557985,"user_tz":-540,"elapsed":13,"user":{"displayName":"G.M. C","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01123269045867249031"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["def preprocess(corpus, source_max_length, target_max_length):\n","  print(\"Reading corpus...\")\n","  pairs = []\n","  for line in corpus:\n","    pairs.append([s for s in line.strip().lower().split(\"\\t\")])\n","  pairs = [pair for pair in pairs if filter_pair(pair, source_max_length, target_max_length)]\n","\n","  source_vocab = Vocab()\n","  target_vocab = Vocab()\n","\n","  for pair in pairs:\n","    source_vocab.add_vocab(pair[0])\n","    target_vocab.add_vocab(pair[1])\n","  print(f\"Source vocab size = {source_vocab.n_vocab}\")\n","  print(f\"Target vocab size = {target_vocab.n_vocab}\")\n","  \n","  return pairs, source_vocab, target_vocab"],"metadata":{"id":"fAV8XZAOu_Cc","executionInfo":{"status":"ok","timestamp":1647436557986,"user_tz":-540,"elapsed":14,"user":{"displayName":"G.M. C","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01123269045867249031"}}},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":["# Encoder AND Decoder"],"metadata":{"id":"spSEggnsyn3C"}},{"cell_type":"markdown","source":["nn.Module.Embedding  \n","https://tutorials.pytorch.kr/beginner/nlp/word_embeddings_tutorial.html"],"metadata":{"id":"BaddbgAC5Ohv"}},{"cell_type":"code","source":["class Encoder(nn.Module):\n","  def __init__(self, input_size, hidden_size):\n","    # input_size: load_source_vocab.n_vocab, hidden_size: encoder_hidden_size\n","    super(Encoder, self).__init__()\n","    self.hidden_size = hidden_size\n","    self.embedding = nn.Embedding(input_size, hidden_size)\n","    self.gru = nn.GRU(hidden_size, hidden_size)\n","  \n","  def forward(self, x, hidden=None):\n","    # x.shape:      (BatchSize, seq_length, input_size)\n","    # hidden.shape: ()\n","    x = self.embedding(x)\n","    if hidden is None:\n","      x, hidden = self.gru(x)\n","    else:\n","      x, hidden = self.gru(x, hidden)\n","    return x, hidden\n","\n","class Decoder(nn.Module):\n","  def __init__(self, hidden_size, output_size):\n","    # hidden_size: \n","    super(Decoder, self).__init__()\n","    self.hidden_size = hidden_size\n","    self.embedding = nn.Embedding(output_size, hidden_size)\n","    self.gru = nn.GRU(hidden_size, hidden_size)\n","    self.out = nn.Linear(hidden_size, output_size)\n","    self.softmax = nn.LogSoftmax(dim=1)\n","\n","  def forward(self, x, hidden):\n","    x = self.embedding(x).view(1, 1, -1)\n","    x, hidden = self.gru(x, hidden)\n","    x = self.softmax(self.out(x[0]))\n","    return x, hidden  "],"metadata":{"id":"791nBtvLyZhb","executionInfo":{"status":"ok","timestamp":1647436557986,"user_tz":-540,"elapsed":13,"user":{"displayName":"G.M. C","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01123269045867249031"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["embedder = nn.Embedding(10, 20)\n","input123 = torch.Tensor([1, 2, 3,9]).long()"],"metadata":{"id":"hmo18A7W-YW1","executionInfo":{"status":"ok","timestamp":1647436557986,"user_tz":-540,"elapsed":13,"user":{"displayName":"G.M. C","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01123269045867249031"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["input123.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AdAJNbPZ-tSD","executionInfo":{"status":"ok","timestamp":1647436557986,"user_tz":-540,"elapsed":12,"user":{"displayName":"G.M. C","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01123269045867249031"}},"outputId":"6d98c44d-5356-44d7-fbc0-3fe3e12372b7"},"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([4])"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["embedder(input123)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rVJKVptF-gJx","executionInfo":{"status":"ok","timestamp":1647436558547,"user_tz":-540,"elapsed":567,"user":{"displayName":"G.M. C","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01123269045867249031"}},"outputId":"3a369b03-4d6c-4f3d-e58e-3ff033c415bc"},"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ 2.2454,  0.6160,  0.3762,  1.1042, -0.6170, -1.7499,  0.1626,  0.0293,\n","         -0.3601, -1.6311,  1.1393,  1.7534,  0.7022,  0.2545,  1.8988,  0.4140,\n","          0.5596, -0.6938,  0.5742,  0.4515],\n","        [-0.6523,  1.5012, -0.1045,  0.6132,  0.0273,  0.8237, -1.0214, -1.2036,\n","          0.5162,  0.4059, -1.1705, -0.4971,  0.1649,  0.3223, -0.0993,  0.2233,\n","          0.1530, -0.5136,  0.4821, -1.4883],\n","        [ 0.0100,  0.6149, -2.2584, -2.2100, -1.1697, -1.6807,  1.6147, -0.8741,\n","         -1.4947,  0.6618,  1.0413, -0.0086, -0.7682,  0.4890,  0.2287, -0.5541,\n","          1.7901, -1.8499, -0.9343, -1.9813],\n","        [-0.6310, -0.1791, -0.6216, -0.6220,  1.4698, -2.8572,  1.1497,  1.0330,\n","         -0.7888,  1.0258, -1.4246,  2.0814,  0.6188,  0.8315,  0.4887,  0.4206,\n","         -0.4815, -0.3580, -0.3857,  0.3697]], grad_fn=<EmbeddingBackward0>)"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":[""],"metadata":{"id":"HKKxdpgV-gGl","executionInfo":{"status":"ok","timestamp":1647436558548,"user_tz":-540,"elapsed":10,"user":{"displayName":"G.M. C","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01123269045867249031"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"5XmGA7TD-gD9","executionInfo":{"status":"ok","timestamp":1647436558548,"user_tz":-540,"elapsed":9,"user":{"displayName":"G.M. C","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01123269045867249031"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["def tensorize(vocab, sentence):\n","  indexes = [vocab.vocab2index[word] for word in sentence.split(\" \")]\n","  indexes.append(vocab.vocab2index[\"<EOS>\"])\n","  return torch.Tensor(indexes).long().to(device).view(-1, 1)"],"metadata":{"id":"RMXyqvLS4Ro_","executionInfo":{"status":"ok","timestamp":1647436558548,"user_tz":-540,"elapsed":9,"user":{"displayName":"G.M. C","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01123269045867249031"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["def train(pairs, source_vocab, target_vocab, encoder, decoder, n_iter, print_every=1000, learning_rate=0.01):\n","  loss_total = 0\n","\n","  encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n","  decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n","\n","  training_batch = [random.choice(pairs) for _ in range(n_iter)]\n","  training_source = [tensorize(source_vocab, pair[0]) for pair in training_batch]\n","  training_target = [tensorize(target_vocab, pair[1]) for pair in training_batch]\n","\n","  criterion = nn.NLLLoss()\n","\n","  for i in range(1, n_iter+1):\n","    source_tensor = training_source[i-1]\n","    target_tensor = training_target[i-1]\n","    \n","    encoder_hidden = torch.zeros([1, 1, encoder.hidden_size]).to(device)    \n","\n","    encoder_optimizer.zero_grad()\n","    decoder_optimizer.zero_grad()\n","\n","    source_length = source_tensor.size(0)\n","    target_length = target_tensor.size(0)\n","\n","    loss = 0\n","\n","    _, encoder_hidden = encoder(source_tensor)\n","\n","    decoder_input = torch.Tensor([[SOS_token]]).long().to(device)\n","    decoder_hidden = encoder_hidden\n","\n","    for di in range(target_length):\n","      decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n","      loss += criterion(decoder_output, target_tensor[di])\n","      decoder_input = target_tensor[di]\n","\n","    decoder_output, _ = decoder(decoder_input, decoder_hidden)\n","\n","    loss.backward()\n","\n","    encoder_optimizer.step()\n","    decoder_optimizer.step()\n","\n","    loss_iter = loss.item() / target_length\n","    loss_total += loss_iter\n","    \n","    if i % print_every == 0:\n","      loss_avg = loss_total / print_every\n","      loss_total = 0\n","      print(f\"[{i} - {i / n_iter * 100}] loss = {loss_avg:05.4f}\")"],"metadata":{"id":"VwRxt5S3zFcK","executionInfo":{"status":"ok","timestamp":1647436616179,"user_tz":-540,"elapsed":1,"user":{"displayName":"G.M. C","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01123269045867249031"}}},"execution_count":31,"outputs":[]},{"cell_type":"code","source":["def evaluate(pairs, source_vocab, target_vocab, encoder, decoder, target_max_length):\n","  for pair in pairs:\n","    print(\">\", pair[0])\n","    print(\"=\", pair[1])\n","    source_tensor = tensorize(source_vocab, pair[0])\n","    source_length = source_tensor.size()[0]\n","\n","    _, encoder_hidden = encoder(source_tensor)\n","    # encoder_hidden : (D * layers, N, H_out)\n","    decoder_input = torch.Tensor([[SOS_token]], device=device).long()\n","    decoder_hidden = encoder_hidden\n","    decoded_words = []\n","\n","    for di in range(target_max_length):\n","      decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n","      _, top_index = decoder_output.data.topk(1)\n","      if top_index.item() == EOS_token:\n","        decoded_words.append(\"<EOS>\")\n","        break\n","      else:\n","        decoded_words.append(target_vocab.index2vocab[top_index.item()])\n","      decoder_input = top_index.squeeze()\n","    \n","    predict_words = decoded_words\n","    predict_sentence = \" \".join(predict_words)\n","    print(\"<\", predict_sentence)\n","    print(\"\")"],"metadata":{"id":"8hot7yLjtbzs","executionInfo":{"status":"ok","timestamp":1647436657308,"user_tz":-540,"elapsed":1,"user":{"displayName":"G.M. C","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01123269045867249031"}}},"execution_count":40,"outputs":[]},{"cell_type":"markdown","source":["# Main process"],"metadata":{"id":"5pL7yph2xGcS"}},{"cell_type":"code","source":["SOURCE_MAX_LENGTH = 10\n","TARGET_MAX_LENGTH = 12"],"metadata":{"id":"6TpXQw_Kug0_","executionInfo":{"status":"ok","timestamp":1647436659148,"user_tz":-540,"elapsed":2,"user":{"displayName":"G.M. C","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01123269045867249031"}}},"execution_count":43,"outputs":[]},{"cell_type":"code","source":["load_pairs, load_source_vocab, load_target_vocab = preprocess(raw, SOURCE_MAX_LENGTH, TARGET_MAX_LENGTH)\n","print(load_pairs)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RYTNv72LxNdQ","executionInfo":{"status":"ok","timestamp":1647436659149,"user_tz":-540,"elapsed":3,"user":{"displayName":"G.M. C","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01123269045867249031"}},"outputId":"59743117-fb69-46b7-fccf-ee71ea897421"},"execution_count":44,"outputs":[{"output_type":"stream","name":"stdout","text":["Reading corpus...\n","Source vocab size = 17\n","Target vocab size = 13\n","[['i feel hungry.', '나는 배가 고프다.'], ['pytorch is very easy.', '파이토치는 매우 쉽다.'], ['pytorch is a framework for deep learning.', '파이토치는 딥러닝을 위한 프레임워크이다.'], ['pytorch is very clear to use.', '파이토치는 사용하기 매우 직관적이다.']]\n"]}]},{"cell_type":"code","source":["encoder_hidden_size = 16\n","decoder_hidden_size = encoder_hidden_size\n","\n","encoder = Encoder(load_source_vocab.n_vocab, encoder_hidden_size).to(device)\n","decoder = Decoder(decoder_hidden_size, load_target_vocab.n_vocab).to(device)"],"metadata":{"id":"SBRV9PzXxah_","executionInfo":{"status":"ok","timestamp":1647436659550,"user_tz":-540,"elapsed":3,"user":{"displayName":"G.M. C","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01123269045867249031"}}},"execution_count":45,"outputs":[]},{"cell_type":"code","source":["train(load_pairs, load_source_vocab, load_target_vocab, encoder, decoder, 5000, print_every=1000)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E6EuDMGA5FJW","executionInfo":{"status":"ok","timestamp":1647436674278,"user_tz":-540,"elapsed":14731,"user":{"displayName":"G.M. C","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01123269045867249031"}},"outputId":"dcad083d-87fc-4c26-cdae-d31274732f45"},"execution_count":46,"outputs":[{"output_type":"stream","name":"stdout","text":["[1000 - 20.0] loss = 0.7020\n","[2000 - 40.0] loss = 0.0997\n","[3000 - 60.0] loss = 0.0315\n","[4000 - 80.0] loss = 0.0163\n","[5000 - 100.0] loss = 0.0110\n"]}]},{"cell_type":"code","source":["evaluate(load_pairs, load_source_vocab, load_target_vocab, encoder, decoder, TARGET_MAX_LENGTH)"],"metadata":{"id":"I7sj6SRB9_29","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1647436674278,"user_tz":-540,"elapsed":6,"user":{"displayName":"G.M. C","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01123269045867249031"}},"outputId":"8f06e6a8-a8af-4830-a851-4182c2c1eb19"},"execution_count":47,"outputs":[{"output_type":"stream","name":"stdout","text":["> i feel hungry.\n","= 나는 배가 고프다.\n","< 나는 배가 고프다. <EOS>\n","\n","> pytorch is very easy.\n","= 파이토치는 매우 쉽다.\n","< 파이토치는 매우 쉽다. <EOS>\n","\n","> pytorch is a framework for deep learning.\n","= 파이토치는 딥러닝을 위한 프레임워크이다.\n","< 파이토치는 딥러닝을 위한 프레임워크이다. <EOS>\n","\n","> pytorch is very clear to use.\n","= 파이토치는 사용하기 매우 직관적이다.\n","< 파이토치는 사용하기 매우 직관적이다. <EOS>\n","\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"FKb9vce94EWw","executionInfo":{"status":"ok","timestamp":1647436674279,"user_tz":-540,"elapsed":3,"user":{"displayName":"G.M. C","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01123269045867249031"}}},"execution_count":47,"outputs":[]}]}